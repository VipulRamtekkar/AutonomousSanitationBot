import cv2
import numpy as np 
import time 
import RPi.GPIO as GPIO 
import pserial 
import picamera 
from tb_ip import *
import math 
import serial
import struct

camera=picamera.PiCamera()

arduino_motor = serial.Serial('com3',9600,timeout=1)
arduino_servo = serial.Serial('com4',9600,timeout=1)

def find_yellow(image):    #returns only the red colors in the frame
    hsv_roi =  cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    mask= cv2.inRange(hsv_roi, np.array([20,150,150]), np.array([30,255,255]))
    #ycr_roi=cv2.cvtColor(image,cv2.COLOR_BGR2YCrCb)
    #mask_2=cv2.inRange(ycr_roi, np.array((0.,165.,165.)), np.array((255.,255.,255.)))
    #mask =cv2.bitwise_or(mask_1,mask_2)
    kern_dilate = np.ones((8,8),np.uint8)
    kern_erode  = np.ones((3,3),np.uint8)
    mask= cv2.erode(mask,kern_erode)      #Eroding
    mask=cv2.dilate(mask,kern_dilate)     #Dilating
    return mask

def contourDetect(gray):
    
    #gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
    gray=cv2.GaussianBlur(gray,(9,9),0)
    edge=cv2.Canny(gray,20,120)
    edge=cv2.dilate(edge,None,iterations=1)
    edge=cv2.erode(edge,None,iterations=1)
    (_, contours, _) = cv2.findContours(edge.copy(), mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)
    for c in contours:
        #c=max(contours,cv2.contourArea)
        found=cv2.minAreaRect(c)
        box=np.int0(cv2.boxPoints(found))
        cv2.drawContours(gray, [box], -1, (255, 255, 255),1)
    return gray

def find_trash(image):
    hsv_roi =  cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    mask= cv2.inRange(hsv_roi, np.array([150,150,150]), np.array([170,255,255]))
    #ycr_roi=cv2.cvtColor(image,cv2.COLOR_BGR2YCrCb)
    #mask_2=cv2.inRange(ycr_roi, np.array((0.,165.,165.)), np.array((255.,255.,255.)))
    #mask =cv2.bitwise_or(mask_1,mask_2)
    kern_dilate = np.ones((8,8),np.uint8)
    kern_erode  = np.ones((3,3),np.uint8)
    mask= cv2.erode(mask,kern_erode)      #Eroding
    mask=cv2.dilate(mask,kern_dilate)     #Dilating
    return mask
    



# initializing the camera 
def startcam():
	camera.start_preview()
	time.sleep(1)

def right_rotation(time_rot): 	                                              # .2.0.0.1.time.  ( time to angle mapping)
	arduino_motor.write(struct.pack('.2.0.0.1.'+ str(time_rot)+'.' )
	
def left_rotation():			                                      # .2.0.0.2.time.
	arduino_motor.write(struct.pack('.2.0.0.1.'+ str(time_rot)+'.') 
					
def move_forward():                                  # .1.1.90>.0.0. : continously move forwad at max speed .1.1.<90.0.0. : ultrasonic on now and move according to it .1.2.0.0.0 increment in forward  
	arduino_motor.write(struct.pack('.1.1.'+str(dist)+'.0.0.')

def move_forward_incr():
	arduino_motor.write(struct.pack('.1.2.0.0.0.')

def move_backward():			                                      # .1.3.0.0.0 
	arduino_motor.write(struct.pack('.1.3.0.0.0.')

def lift_arm(angle):
                                                                              #Start the serial port to communicate with arduino
		
	pos = angle
	data.write(struct.pack('>B',pos))
	return null                                                          #code and send the angle to the Arduino through serial port

def open_flap(): 
	
	pos =180 #open flap                        
	data.write(struct.pack('>B',pos))
	time.sleep(1)
	pos=90	#close flap
	data.write(struct.pack('>B',pos))
	return null

def captureImg():                                                           # the entire patch goes in the while loop for iteration 
	camera.capture('runimg.jpg')
	img = cv2.imread('runimg.jpg', 1)
	return img

def stopCam():                                                             # stoping the preview of the camera
	camera.stop_preview()
def open_water(): 
	arduino_servo.write(struct.pack('o'))

def distance_estimate(c):                                                  #takes in contours 
	'''
	def find_marker(image):
		gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
		gray = cv2.GaussianBlur(gray, (5, 5), 0)
		edged = cv2.Canny(gray, 35, 125)
		(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
		c = max(cnts, key = cv2.contourArea)
		cv2.imshow("edged",edged)
		return cv2.minAreaRect(c)
		'''

	def distance_to_camera(knownWidth, focalLength, perWidth):
		return (knownWidth * focalLength) / perWidth

	marker=cv2.minAreaRect(c)
	KNOWN_DISTANCE = 12.0
	KNOWN_WIDTH = 11.0

	#marker = find_marker(image)
	focalLength = (marker[1][0] * KNOWN_DISTANCE) / KNOWN_WIDTH
	#for imagePath in IMAGE_PATHS:
	#image = cv2.imread(imagePath)
	#marker = find_marker(image)
	inches = distance_to_camera(KNOWN_WIDTH, focalLength, marker[1][0])
	
	return inches 
	'''
	box = np.int0(cv2.cv.BoxPoints(marker))
	cv2.drawContours(image, [box], -1, (0, 255, 0), 2)
	cv2.putText(image, "%.2fft" % (inches / 12),
		(image.shape[1] - 200, image.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX,
		2.0, (0, 255, 0), 3)
	cv2.imshow("image", image)
	cv2.waitKey(0)
	'''
if __name__="__main__":

	start_time=time.time()
	startcam()         # the stains code patch will run for about 420 seconds and then the second patch will start 

	while ((time.time()-start_time) < 420):
		im=captureImg()
		#now the image has been captured which needs to be processed for the 
		#stain detection 
		mask=yellow_detect(im)
		#the contour detection        
		#finding the center of the object detected
	while ((time.time()-start_time) < 420):
		#trash picking 
		im=captureImg()
		#now filter the trash pieces out of the image 
		#find the center of the trash piece
		while not contourDetect():
			#keep turning 
		#Now the object has been detected 
		#get the distance estimate 
		#open the servo flap

	while ((time.time()-start_time) < 420):
		#toilet detection 
		#find the contour of the toilet
		while not contourDetect():
			#keep turning 
		#Now the object has been detected 
		#get the distance estimate 
	#to return to its initial posiiton the patch would be coming back directly
	#signal to take a 360degree turn and then move forward till the 
	#sonar tells to stop, would partially call for the return
	stopCam()



















